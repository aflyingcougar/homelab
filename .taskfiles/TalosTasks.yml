---
version: "3"

tasks:
  silent: true
  init:
    desc: Generate and validate configuration files
    dir: "{{.TALOS_DIR}}"
    deps: [gen-config]
    cmds:
      - talosctl validate --mode cloud --config <(sops --decrypt controlplane.sops.yaml)
      - talosctl validate --mode cloud --config <(sops --decrypt worker.sops.yaml)
    preconditions:
      - sh: test -f {{.SOPS_AGE_KEY_FILE}}
        msg: |
          Age key file is not found. Did you forget to create it?
    vars:
      SOPS_AGE_KEY_FILE: ~/.config/sops/age/keys.txt

  gen-config:
    desc: Generate base configuration files and encrypt
    dir: "{{.TALOS_DIR}}"
    cmds:
      - talosctl gen config homelab-{{.BOOTSTRAP_ENV}}-cluster https://{{.BOOTSTRAP_TALOS_VIP_ADDR}}:6443 --config-patch-control-plane @cp.patch.yaml --config-patch @all.patch.yaml {{.CLI_ARGS}}
      - mv controlplane.yaml controlplane.sops.yaml
      - mv worker.yaml worker.sops.yaml
      - mv talosconfig {{.ROOT_DIR}}/talosconfig
      - sops --encrypt --in-place controlplane.sops.yaml
      - sops --encrypt --in-place worker.sops.yaml
    sources:
      - cp.patch.yaml
      - all.patch.yaml
    generates:
      - controlplane.sops.yaml
      - worker.sops.yaml
      - "{{.ROOT_DIR}}/talosconfig"
    preconditions:
      - sh: test -f {{.SOPS_AGE_KEY_FILE}}
        msg: |
          Age key file is not found. Did you forget to create it?
    vars:
      SOPS_AGE_KEY_FILE: ~/.config/sops/age/keys.txt

  bootstrap:
    desc: Bootstrap the talos cluster
    dir: "{{.TALOS_DIR}}"
    cmds:
      # - task: create-vms
      #   silent: true
      #   ignore_error: true  # hacky way to make this command optional
      - task: ping-cluster
        vars: { NODES: all, PORT: 50000 }
      - task: ping-cluster
        vars: { NODES: control, PORT: 50001 }
      - echo "Bootstrapping the cluster..."
      - talosctl bootstrap -e {{.BOOTSTRAP_TALOS_HOST_ADDR_0}} -n {{.BOOTSTRAP_TALOS_HOST_ADDR_0}}
      - talosctl config endpoint {{.BOOTSTRAP_TALOS_HOST_ADDR_0}}
      - talosctl config node {{.BOOTSTRAP_TALOS_HOST_ADDR_0}}
      - task: ping-cluster
        vars: { NODES: all, PORT: 50000 }
      - task: ping-cluster
        vars: { NODES: control, PORT: 50001 }
      - talosctl kubeconfig {{.ROOT_DIR}}
      - echo "The kubeconfig has been copied to '{{.ROOT_DIR}}'"
      - echo "Waiting for control plane to become available..."
      - task: ping-cluster
        vars: { NODES: control, PORT: 6443 }
      - task: deploy-cilium
      - echo "Waiting for cluster to be healthy..."
      - talosctl health
      - echo "Cluster bootstrap successful."

  create-vms:
    silent: true
    desc: (Staging only) Create VMs for talos cluster
    dir: "{{.TALOS_DIR}}"
    preconditions:
      - sh: '[ "${BOOTSTRAP_ENV}" = "staging" ]'
        msg: "Skipping VM creation, because the environment is not 'staging'."
      - sh: test -f {{.TALOS_DIR}}/controlplane.sops.yaml
        msg: |
          Control plane machine config was not found. Did you forget to create it?
      - sh: test -f {{.TALOS_DIR}}/worker.sops.yaml
        msg: |
          Worker machine config was not found. Did you forget to create it?
    cmds:
      - echo "Creating VMs for staging environment..."
      - task: :terraform:vsphere-init
      - cmd: task terraform:vsphere-apply -- -auto-approve -var="control_machine_config={{.ENCODED_CONTROL_CONFIG}}" -var="worker_machine_config={{.ENCODED_WORKER_CONFIG}}"
        silent: true
    vars:
      ENCODED_CONTROL_CONFIG:
        sh: sops --decrypt {{.TALOS_DIR}}/controlplane.sops.yaml | base64
      ENCODED_WORKER_CONFIG:
        sh: sops --decrypt {{.TALOS_DIR}}/worker.sops.yaml | base64

  deploy-cilium:
    internal: false
    desc: Deploy Cilium CNI (with kube-proxy)
    dir: "{{.TALOS_DIR}}"
    cmds:
      - echo "Attemping to deploy Cilium..."
      - echo "Checking prerequisites..."
      - task: cilium-prereqs
      - echo "Deploying Cilium..."
      - |
        helm template \
            cilium \
            cilium/cilium \
            --version 1.15.6 \
            --namespace kube-system \
            --set ipam.mode=kubernetes \
            --set kubeProxyReplacement=false \
            --set securityContext.capabilities.ciliumAgent="{CHOWN,KILL,NET_ADMIN,NET_RAW,IPC_LOCK,SYS_ADMIN,SYS_RESOURCE,DAC_OVERRIDE,FOWNER,SETGID,SETUID}" \
            --set securityContext.capabilities.cleanCiliumState="{NET_ADMIN,SYS_ADMIN,SYS_RESOURCE}" \
            --set cgroup.autoMount.enabled=false \
            --set cgroup.hostRoot=/sys/fs/cgroup > cilium.yaml
      - kubectl apply -f cilium.yaml
      - rm -f cilium.yaml

  cilium-prereqs:
    internal: true
    desc: Checks for helm repo and machine config
    dir: "{{.TALOS_DIR}}"
    cmds:
      - echo "Checking for cilium helm repo..."
      - |
        if [[ ! $(helm repo list | grep cilium) ]]; then
          helm repo add cilium https://helm.cilium.io
          helm repo update
        fi
        echo "Cilium helm repo located."
      - echo "Checking for valid machine config..."
      - |
        if [[ "$(talosctl get mc -o yaml -n {{.BOOTSTRAP_TALOS_HOST_ADDR_0}} | yq '.spec' | yq '.cluster.network.cni.name')" != "none" ]]; then
          echo "Control plane machine config does not have CNI set to 'none'. Did you forget to run 'task talos:init'?"
          exit 1
        fi
        echo "Control plane machine config verified."
        if [[ "$(talosctl get mc -o yaml -n {{.BOOTSTRAP_TALOS_HOST_ADDR_3}} | yq '.spec' | yq '.cluster.network.cni.name')" != "none" ]]; then
          echo "Worker machine config does not have CNI set to 'none'. Did you forget to run 'task talos:init'?"
          exit 1
        fi
        echo "Worker machine config verified."
    preconditions:
      - sh: test -f {{.SOPS_AGE_KEY_FILE}}
        msg: |
          Age key file is not found. Did you forget to create it?
    vars:
      SOPS_AGE_KEY_FILE: ~/.config/sops/age/keys.txt

  nuke:
    silent: true
    desc: 'Resets all nodes'
    dir: "{{.TALOS_DIR}}"
    cmds:
      - talosctl reset --wait -n {{.BOOTSTRAP_TALOS_HOST_ADDR_1}},{{.BOOTSTRAP_TALOS_HOST_ADDR_2}},{{.BOOTSTRAP_TALOS_HOST_ADDR_3}},{{.BOOTSTRAP_TALOS_HOST_ADDR_4}}
      - talosctl reset --graceful=false -n {{.BOOTSTRAP_TALOS_HOST_ADDR_0}}

  ping-cluster:
    silent: true
    desc: 'Tests connectivity specified hosts and TCP port'
    dir: "{{.TALOS_DIR}}"
    cmds:
      - echo "Testing {{.NODES}} connectivity..."
      - |
        host_reachable=false
        for var in "${!BOOTSTRAP_TALOS_HOST_ADDR_@}"; do
          node_id="${var##*_}"
          node_control="BOOTSTRAP_TALOS_CONTROL_NODE_${node_id}"
          if [[ {{.NODES}} == "all" ]]; then
            task talos:tcp-ping HOST=${!var} PORT={{.PORT}}
          elif [[ "${!node_control}" == "true" && {{.NODES}} == "control" ]]; then
            task talos:tcp-ping HOST=${!var} PORT={{.PORT}}
          elif [[ "${!node_control}" == "false" && {{.NODES}} == "worker" ]]; then
            task talos:tcp-ping HOST=${!var} PORT={{.PORT}}
          else
            continue
          fi
        done
    requires:
      vars:
        - name: NODES
          enum: [all, control, worker]
        - name: PORT

  tcp-ping:
    silent: true
    desc: Tests connection to TCP 'PORT' at 'HOST'
    dir: "{{.TALOS_DIR}}"
    cmds:
      - |
        host_reachable=false
        for i in {1..{{.PING_MAX_ATTEMPTS}}}; do
          if nc -z {{.HOST}} {{.PORT}} &> /dev/null; then
            echo "Host at {{.HOST}} is reachable at TCP {{.PORT}}."
            host_reachable=true
            break
          else
            echo "Host at {{.HOST}} is not reachable at TCP {{.PORT}}. Retrying in {{.PING_SLEEP}} seconds..."
            sleep {{.PING_SLEEP}}
          fi
        done
        if [[ "$host_reachable" == false ]]; then
          echo "ERROR: Node at {{.HOST}} is unreachable at TCP {{.PORT}} after {{.PING_MAX_ATTEMPTS}} attempts."
          exit 1
        fi
    vars:
      PING_MAX_ATTEMPTS: 60
      PING_SLEEP: 10
      HOST: '{{.HOST}}'
      PORT: '{{.PORT}}'
